# -*- coding: utf-8 -*-
"""phân_loại_end_vgg16.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IvHLqcl_ISyCtpZ5MwB5vm80R6vWz8Er
"""

from google.colab import drive
drive.mount('/content/drive')

from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.layers import Input, Flatten, Dense, Dropout
from tensorflow.keras.models import Model
import matplotlib.pyplot as plt
import numpy as np
import os
import glob
import cv2

from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
n_epochs = 50

image_size = 224
data_path="/content/drive/MyDrive/20.05.2023/classification/data/data_end"
class_names = ['glioma', 'meningioma','notumor','pituitary']

def build_model(image_size=image_size, n_class=len(class_names)):
    # Su dung CNN VGG16
    model_vgg16_conv = VGG16(weights='imagenet', include_top=False)

    # Dong bang cac layer
    for layer in model_vgg16_conv.layers:
        layer.trainable = False

    # Tao model
    input = Input(shape=(image_size, image_size, 3), name='image_input')
    output_vgg16_conv = model_vgg16_conv(input)

    # Them cac layer FC va Dropout
    x = Flatten(name='flatten')(output_vgg16_conv)
    x = Dense(4096, activation='relu', name='fc1')(x)
    x = Dropout(0.5)(x)
    x = Dense(4096, activation='relu', name='fc2')(x)
    x = Dropout(0.5)(x)
    x = Dense(n_class, activation='softmax', name='predictions')(x)

    # Compile
    my_model = Model(inputs=input, outputs=x)
    my_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

    return my_model

def load_data(data_path, class_names, image_size):
    data = []
    label = []
    for i_class in class_names:
        read_path = os.path.join(data_path, i_class,"*")
        print(read_path)
        for file in glob.glob(read_path):
            # Read
            print(file)
            image = cv2.imread(file)
            # Resize
            image = cv2.resize(image, dsize=(image_size, image_size))
            # Add to data
            data.append(image)
            label.append(i_class)

    # Encode labels from text to onehot
    label_encoder = LabelEncoder()
    integer_encoded = label_encoder.fit_transform(label)
    onehot_encoder = OneHotEncoder(sparse=False)
    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)
    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)

    # Change to numpy array
    label = onehot_encoded
    data = np.array(data)
    return data, label

# Make model
my_model = build_model(image_size, len(class_names))

# Compile model
my_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Load data from folder
X_train, y_train = load_data('/content/drive/MyDrive/20.05.2023/classification/data/data_end/Training', class_names, image_size)
X_test, y_test = load_data('/content/drive/MyDrive/20.05.2023/classification/data/data_end/Testing', class_names, image_size)

my_model = build_model(image_size, len(class_names))
# Train the model and get the history
history = my_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))

from sklearn.metrics import confusion_matrix

y_prediction = my_model.predict(X_test)
y_prediction = np.argmax (y_prediction, axis = 1)
y_test=np.argmax(y_test, axis=1)
result = confusion_matrix(y_test, y_prediction , normalize='pred')
print(result)

from sklearn.metrics import classification_report, ConfusionMatrixDisplay

target_names = ['glioma', 'meningioma', 'notumor','pituitary']

print(classification_report(y_test, y_prediction, target_names=target_names))

ConfusionMatrixDisplay.from_predictions(
    y_test, y_prediction
)
print("\nConfusion matrix: X-Dự Đoán \t Y-Nhãn Thật\n0-Glioma\t1-Meningioma\t\t2-Noturmor\t 3-Pituitary")

accurary = max(history.history['val_accuracy'])
print("Đô chính xác: ", accurary)

train_acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
train_loss = history.history['loss']
val_loss = history.history['val_loss']

# Vẽ biểu đồ độ chính xác
plt.plot(train_acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.title('Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')
plt.show()

# Vẽ biểu đồ mất mát
plt.plot(train_loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.title('Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(loc='upper right')
plt.show()

my_model.save(os.path.join("/content/drive/MyDrive", "modelvgg16.h5"))

from tensorflow.keras.models import load_model
from google.colab.patches import cv2_imshow
import os
import cv2
import tensorflow as tf
import numpy as np

from tensorflow.keras.models import load_model
from google.colab.patches import cv2_imshow
import numpy as np
import matplotlib.pyplot as plt
import cv2
import tensorflow as tf
model_path = ('/content/drive/MyDrive/modelvgg16.h5')
target_names = ['glioma', 'meningioma', 'notumor','pituitary']

def predict_class_img_with_img(img_path):
    class_names = ['glioma', 'meningioma', 'notumor', 'pituitary']
    # load model
    model = load_model(model_path)
    img_arr = cv2.imread(img_path)
    image = cv2.resize(img_arr, dsize=(224, 224))

    # print(np_img.shape)
    image = np.expand_dims(image, axis=0)

    predictions = model.predict(image)
    print(predictions)
    best = np.argmax(predictions[0], axis=0)
    score = predictions[0][best]
    print(score)

    print(f"Label is {class_names[int(best)]}, score is {score * 100}%")
    cv2_imshow(image[0])
    # return class_names[int(pred_labels)]

img_path ='/content/drive/MyDrive/20.05.2023/classification/data/data_vgg16/Training/glioma/Te-gl_0042.jpg'
predict_class_img_with_img(img_path)

"""tf.nn.sigmoid là hàm active multilabel
lablel classification

4: 1 não
"""

model = load_model(model_path)

from google.colab import drive
drive.mount('/content/drive')

from sklearn.metrics import confusion_matrix
target_names = ['glioma', 'meningioma', 'notumor','pituitary']

image = cv2.imread(img_path)
# Resize
image = cv2.resize(image, dsize=(224, 224))
image = np.expand_dims(image, axis=0)
# np_arr = np.array(image)
y_prediction = model.predict(image)
print(y_prediction)
y_prediction = np.argmax (y_prediction, axis = 0)
y_test=np.argmax(y_prediction, axis=0)
# result = confusion_matrix(y_test, y_prediction , normalize='pred')
print(target_names[y_test])

img_path ='/content/drive/MyDrive/20.05.2023/classification/data/data_vgg16/Training/meningioma/Te-me_0025.jpg'
predict_class_img_with_img(img_path)

img_path ='/content/drive/MyDrive/20.05.2023/classification/data/data_vgg16/Training/notumor/Tr-no_0597.jpg'
predict_class_img_with_img(img_path)

img_path ='/content/drive/MyDrive/20.05.2023/classification/data/data_vgg16/Training/pituitary/Te-pi_0157.jpg'
predict_class_img_with_img(img_path)