# -*- coding: utf-8 -*-
"""train_segment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15HSKh5ye8jElhO3DnbyTP9hWBiJbfMmA
"""

from google.colab import drive
drive.mount('/content/gdrive')

# imports
sys.path.insert(1,'/content/gdrive/MyDrive/20.05.2023/segmentation')
import model_bt
from tensorflow.keras.models import save_model, Model
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.optimizers import Adam
import cv2
import glob
import skimage.transform as trans
import numpy as np
import matplotlib.pyplot as plt
import os
import model_bt

!cp /content/gdrive/MyDrive/DATN_20.05.2023.rar /content

!unrar x /content/DATN_20.05.2023.rar

import os

xt_path = "/content/gdrive/MyDrive/20.05.2023/segmentation/re_process/image"
xt_images = glob.glob(xt_path + "*.png")
xt_images.sort()
x_t_avoid = []
for x in xt_images:
  x_t_avoid.append(os.path.basename(x))

xa_path = "/content/gdrive/MyDrive/20.05.2023/segmentation/re_process/anno"
xa_images = glob.glob(xa_path + "*.png")
xa_images.sort()
x_a_avoid = []
for x in xa_images:
  x_a_avoid.append(os.path.basename(x))

xt_path = "/content/gdrive/MyDrive/20.05.2023/segmentation/re_process/images"
xt_images = glob.glob(xt_path + "*.png")
xt_images.sort()
x_t = []
for img in xt_images:
   if os.path.basename(img) not in x_t_avoid:
    image = cv2.imread(img, cv2.IMREAD_GRAYSCALE)
    image = image / 255
    image = trans.resize(image,(256,256))
    x_t.append(image)


xa_path = "/content/gdrive/MyDrive/20.05.2023/segmentation/re_process/annotations"
xa_images = glob.glob(xa_path + "*.png")
xa_images.sort()
x_a = []
for msk in xa_images:
   if os.path.basename(msk) not in x_t_avoid:
    mask = cv2.imread(msk)
    mask = mask /255
    mask = trans.resize(mask,(256,256))
    mask[mask != 0] = 1
    x_a.append(mask)

mask = cv2.imread("/content/gdrive/MyDrive/20.05.2023/segmentation/re_process/anno/y1061.png")
mask = mask /255
mask = trans.resize(mask,(256,256))
white_pixels = np.where((mask[:, :, 0] == 255) &
                        (mask[:, :, 1] == 255) &
                        (mask[:, :, 2] == 255))

mask[white_pixels] = [0, 0, 0]
mask[mask != 0] = 1

plt.subplot(2,3,5),plt.imshow(mask,'gray',vmin=0,vmax=255)
 plt.title('tem')
 plt.xticks([]),plt.yticks([])

# prepare data
x_t = np.array(x_t)
x_a = np.array(x_a)
# y_t = np.array(y_t)
# y_a = np.array(y_a)
x_t = np.reshape(x_t, (len(x_t), 256, 256, 1))
# x_a = np.reshape(x_a, (len(x_a), 256, 256, 1))
#y_t = np.reshape(y_t, (len(y_t), 512, 512, 1))
#y_a = np.reshape(y_a, (len(y_a), 512, 512, 1))

import glob
import cv2
import numpy as np
from sklearn.model_selection import train_test_split
from skimage import transform
from imblearn.over_sampling import RandomOverSampler

# Define paths to train and test data
train_images_path = "/content/gdrive/MyDrive/20.05.2023/segmentation/re_process/images1/Train/"
train_annotations_path = "/content/gdrive/MyDrive/20.05.2023/segmentation/re_process/annotations1/Train/"

test_images_path = "/content/gdrive/MyDrive/20.05.2023/segmentation/re_process/images1/Test/"
test_annotations_path = "/content/gdrive/MyDrive/20.05.2023/segmentation/re_process/annotations1/Test/"

# Load train image data
train_xt_images = glob.glob(train_images_path + "*.png")
train_xt_images.sort()
train_x_t = []
for img in train_xt_images:
    image = cv2.imread(img, cv2.IMREAD_GRAYSCALE)
    image = image / 255.0
    image = transform.resize(image, (256, 256))
    train_x_t.append(image)

# Load train annotation data
train_xa_images = glob.glob(train_annotations_path + "*.png")
train_xa_images.sort()
train_x_a = []
for msk in train_xa_images:
    mask = cv2.imread(msk, cv2.IMREAD_GRAYSCALE)
    mask = mask / 255.0
    mask = transform.resize(mask, (256, 256))
    mask[mask != 0] = 1
    train_x_a.append(mask)

# Load test image data
test_xt_images = glob.glob(test_images_path + "*.png")
test_xt_images.sort()
test_x_t = []
for img in test_xt_images:
    image = cv2.imread(img, cv2.IMREAD_GRAYSCALE)
    image = image / 255.0
    image = transform.resize(image, (256, 256))
    test_x_t.append(image)

# Load test annotation data
test_xa_images = glob.glob(test_annotations_path + "*.png")
test_xa_images.sort()
test_x_a = []
for msk in test_xa_images:
    mask = cv2.imread(msk, cv2.IMREAD_GRAYSCALE)
    mask = mask / 255.0
    mask = transform.resize(mask, (256, 256))
    mask[mask != 0] = 1
    test_x_a.append(mask)

# Convert the lists to numpy arrays
X_train = np.array(train_x_t)
y_train = np.array(train_x_a)
X_test = np.array(test_x_t)
y_test = np.array(test_x_a)

from collections import Counter
import numpy as np

# Reshape X_train and y_train to 2D arrays
X_train_flat = X_train.reshape(X_train.shape[0], -1)
y_train_flat = y_train.reshape(y_train.shape[0], -1)

# Get the class distribution of y_train
class_distribution = Counter(tuple(row) for row in y_train_flat)

# Find the maximum number of samples among the classes
max_samples = max(class_distribution.values())

# Create arrays to store oversampled data
X_train_oversampled = []
y_train_oversampled = []

# Oversample each class to have the same number of samples as the maximum class
for class_label, count in class_distribution.items():
    X_class = X_train_flat[np.all(y_train_flat == class_label, axis=1)]
    y_class = y_train_flat[np.all(y_train_flat == class_label, axis=1)]

    if count < max_samples:
        # Calculate the number of additional samples to generate
        num_samples = max_samples - count

        # Randomly select samples from the current class with replacement
        indices = np.random.choice(np.arange(count), size=num_samples, replace=True)
        X_oversampled = X_class[indices]
        y_oversampled = y_class[indices]

        # Add the oversampled data to the arrays
        X_train_oversampled.append(X_oversampled)
        y_train_oversampled.append(y_oversampled)

# Concatenate the oversampled data
X_train_oversampled = np.concatenate(X_train_oversampled, axis=0)
y_train_oversampled = np.concatenate(y_train_oversampled, axis=0)

# Reshape X_train_oversampled and y_train_oversampled back to 3D arrays
X_train_oversampled = X_train_oversampled.reshape(X_train_oversampled.shape[0], X_train.shape[1], X_train.shape[2])
y_train_oversampled = y_train_oversampled.reshape(y_train_oversampled.shape[0], y_train.shape[1], y_train.shape[2])

# Print the number of samples after oversampling
print("Number of samples after oversampling:")
print("X_train:", X_train_oversampled.shape[0])
print("y_train:", y_train_oversampled.shape[0])

from sklearn.model_selection import KFold
from tensorflow.keras.layers import Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

# Số lượng fold
k = 5

# Khởi tạo K-fold cross-validation
kf = KFold(n_splits=k, shuffle=True)

# Danh sách để lưu độ chính xác từng fold
train_accuracies = []
val_accuracies = []

# Lặp qua các fold
for fold_index, (train_index, val_index) in enumerate(kf.split(X_train)):
    # Tạo tập huấn luyện và tập validation dựa trên các chỉ số
    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]
    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]

    # Tạo và huấn luyện mô hình trên tập huấn luyện
    model = model_bt.unet_bt()
    model.compile(optimizer=Adam(learning_rate=1e-4),
                  loss='binary_crossentropy',
                  metrics=['accuracy'])



    # Tạo callback EarlyStopping
    early_stopping = EarlyStopping(monitor='val_loss', patience=10)

    history = model.fit(X_train_fold, y_train_fold,
                        epochs=10,
                        batch_size=2,
                        shuffle=True,
                        validation_data=(X_val_fold, y_val_fold),
                        callbacks=[early_stopping])

    # Đánh giá mô hình trên tập huấn luyện và tập validation
    _, train_accuracy = model.evaluate(X_train_fold, y_train_fold)
    _, val_accuracy = model.evaluate(X_val_fold, y_val_fold)
    train_accuracies.append(train_accuracy)
    val_accuracies.append(val_accuracy)

    # Lưu mô hình
    model.save('/content/gdrive/MyDrive/20.05.2023/segmentation/re_process/model/BTfinderFINAL.h5'.format(fold_index))

    # Kiểm tra số lượng epoch đã đạt tới 10
    if len(history.history['loss']) >= 10:
        break

# Tính trung bình độ chính xác từ các fold
mean_train_accuracy = np.mean(train_accuracies)
mean_val_accuracy = np.mean(val_accuracies)
print("Mean train accuracy:", mean_train_accuracy)
print("Mean validation accuracy:", mean_val_accuracy)

BTfinder.save_weights('/content/gdrive/MyDrive/20.05.2023/segmentation/re_process/model/weights.hdf5')

from tensorflow.keras.models import load_model
from tensorflow.keras import optimizers
import matplotlib.pyplot as plt
yt_path = "/content/segmentation/re_process/imgForTest/"
yt_images = glob.glob(yt_path + "*.jpg")
yt_images.sort()
y_t = []
for img in yt_images:
   image = cv2.imread(img, cv2.IMREAD_GRAYSCALE)
   image = image / 255
   image = trans.resize(image,(256,256))
   y_t.append(image)
for i in range(len(y_t)):
  predicted = model.predict(np.reshape(y_t[i], (1, 256, 256, 1)))
  predicted = np.reshape(predicted, (256, 256))
  predicted = predicted.astype(np.float32) * 255
  cv2.imwrite('/content/y{}.png'.format(i), predicted)

BTfinder.save('/content/gdrive/MyDrive/20.05.2023/segmentation/')

from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dropout, concatenate

def unet_bt(pretrained_weights=None, input_size=(256,256,1)):
    inputs = Input(input_size)
    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)
    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2), strides = 2)(conv1)
    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)
    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2), strides = 2)(conv2)
    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)
    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2), strides = 2)(conv3)
    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)
    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)
    drop4 = Dropout(0.5)(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2), strides = 2)(drop4)
    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)
    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)
    drop5 = Dropout(0.5)(conv5)
    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))
    merge6 = concatenate([drop4,up6], axis = 3)
    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)
    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)
    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))
    merge7 = concatenate([conv3,up7], axis = 3)
    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)
    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)
    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))
    merge8 = concatenate([conv2,up8], axis = 3)
    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)
    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)
    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))
    merge9 = concatenate([conv1,up9], axis = 3)
    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)
    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)

    model = Model(inputs, conv10)
    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])
    if(pretrained_weights):
    	model.load_weights(pretrained_weights)

    return model

"""# đánh giá"""

test_data = '/content/data/segmen_dataset/TEST'

print(len(x_t))
print(len(x_a))

model = unet_bt('/content/gdrive/MyDrive/20.05.2023/segmentation/re_process/model/weights.hdf5')

def calculate_iou(true_mask, pred_mask):
    intersection = np.logical_and(true_mask, pred_mask)
    union = np.logical_or(true_mask, pred_mask)
    iou_score = np.sum(intersection) / np.sum(union)
    return iou_score

list_iou = []
 # Load the images
for index in range(len(x_t)):
  image = x_t[index]
  segment = x_a[index]

  image = np.expand_dims(image, axis=0)
  segment = np.expand_dims(segment, axis=0)

  # Predict the mask using the U-Net model
  predicted_mask = model.predict(image)

  # Threshold the predicted mask if needed
  predicted_mask = (predicted_mask > 0.5).astype(np.uint8)

  # Calculate IoU
  iou = calculate_iou(segment, predicted_mask)
  list_iou.append(iou)

print(sum(list_iou)/len(list_iou))

y_pred = []
for index in range(0,len(x_t)):
  predicted = model.predict(np.reshape(x_t[index], (1, 256, 256, 1)))
  predicted = predicted.astype(np.float64) * 255
  predicted = np.reshape(predicted, (256, 256))
  predicted = predicted.astype(np.uint8)
  predicted = cv2.cvtColor(predicted, cv2.COLOR_GRAY2BGR)
  ret, mask = cv2.threshold(predicted, 120, 255, cv2.THRESH_BINARY)
  white_pixels = np.where((mask[:, :, 0] == 255) &
                        (mask[:, :, 1] == 255) &
                        (mask[:, :, 2] == 255))

  mask[white_pixels] = [255, 255, 255]
  y_pred.append(mask)

calculate_iou(x_a[0],y_pred[0])

list_iou = []
for index in range(0,len(x_t)):
  x = y_pred[index]
  y = x_a[index]
  list_iou.append(calculate_iou(x,y))

print(sum(list_iou)/len(list_iou))